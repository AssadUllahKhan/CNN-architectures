{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3973,"status":"ok","timestamp":1732099561629,"user":{"displayName":"Assad Ullah","userId":"12251528893146048503"},"user_tz":-300},"id":"tZdo9feSCLQS","outputId":"980e59d8-090b-4482-91fd-ae9aaa1c8c02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Path to dataset files: /root/.cache/kagglehub/datasets/borhanitrash/animal-image-classification-dataset/versions/1\n"]}],"source":["# import kagglehub\n","\n","# # Download latest version\n","# path = kagglehub.dataset_download(\"borhanitrash/animal-image-classification-dataset\")\n","\n","# print(\"Path to dataset files:\", path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3823,"status":"ok","timestamp":1732104730465,"user":{"displayName":"Assad Ullah","userId":"12251528893146048503"},"user_tz":-300},"id":"ClMuazjyXCcD","outputId":"40f43186-1253-47df-d612-583f69396448"},"outputs":[{"name":"stdout","output_type":"stream","text":["Path to dataset files: /root/.cache/kagglehub/datasets/javaidahmadwani/sign-language-digits-dataset/versions/1\n"]}],"source":["import kagglehub\n","import os\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"javaidahmadwani/sign-language-digits-dataset\")\n","\n","print(\"Path to dataset files:\", path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"XlSg1zVaDciA","outputId":"5a2bdc81-adc7-47f9-ff22-d5672ce81154"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1712 images belonging to 10 classes.\n","Found 50 images belonging to 10 classes.\n","Found 300 images belonging to 10 classes.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 788ms/step - accuracy: 0.0967 - loss: 2.5865 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 2/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 515ms/step - accuracy: 0.0913 - loss: 2.3039 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 3/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 526ms/step - accuracy: 0.0964 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3028\n","Epoch 4/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 525ms/step - accuracy: 0.0937 - loss: 2.3036 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 5/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 516ms/step - accuracy: 0.0742 - loss: 2.3038 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 6/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 526ms/step - accuracy: 0.1040 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 7/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 526ms/step - accuracy: 0.0859 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 8/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 522ms/step - accuracy: 0.1033 - loss: 2.3027 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 9/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 530ms/step - accuracy: 0.0906 - loss: 2.3032 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 10/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 526ms/step - accuracy: 0.0939 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 11/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 523ms/step - accuracy: 0.0992 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 12/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 529ms/step - accuracy: 0.1024 - loss: 2.3028 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 13/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 514ms/step - accuracy: 0.1002 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 14/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 534ms/step - accuracy: 0.0932 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 15/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 526ms/step - accuracy: 0.0885 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 16/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 517ms/step - accuracy: 0.0849 - loss: 2.3034 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 17/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 520ms/step - accuracy: 0.1095 - loss: 2.3019 - val_accuracy: 0.1000 - val_loss: 2.3027\n","Epoch 18/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.0840 - loss: 2.3033 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 19/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 519ms/step - accuracy: 0.0814 - loss: 2.3031 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 20/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 524ms/step - accuracy: 0.0969 - loss: 2.3024 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 21/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 508ms/step - accuracy: 0.0933 - loss: 2.3027 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 22/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 528ms/step - accuracy: 0.0970 - loss: 2.3024 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 23/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 522ms/step - accuracy: 0.0791 - loss: 2.3030 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 24/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 515ms/step - accuracy: 0.0898 - loss: 2.3029 - val_accuracy: 0.1000 - val_loss: 2.3026\n","Epoch 25/25\n","\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 524ms/step - accuracy: 0.1001 - loss: 2.3028 - val_accuracy: 0.1000 - val_loss: 2.3026\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 924ms/step - accuracy: 0.0907 - loss: 2.3034\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.1000\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Set paths to your training, validation, and test directories\n","train_dir = os.path.join(path, 'Sign-Language-Digits-Datase/train')\n","val_dir = os.path.join(path, 'Sign-Language-Digits-Datase/test')\n","test_dir = os.path.join(path, 'Sign-Language-Digits-Datase/valid')\n","\n","# Image parameters\n","img_height = 224\n","img_width = 224\n","batch_size = 32\n","\n","# Data generators with data augmentation for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Validation and Test data generators (no augmentation)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow data from directories\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Build the VGG-16 model\n","vgg16_model = models.Sequential([\n","    # VGG-16 Pre-trained Model\n","    layers.InputLayer(input_shape=(img_height, img_width, 3)),\n","    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2), strides=2),\n","\n","    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2), strides=2),\n","\n","    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2), strides=2),\n","\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2), strides=2),\n","\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n","    layers.MaxPooling2D((2, 2), strides=2),\n","\n","    # Flatten the feature maps\n","    layers.Flatten(),\n","    layers.Dense(4096, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(4096, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(10, activation='softmax')  # 10 classes\n","])\n","\n","# Compile the model\n","vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = vgg16_model.fit(\n","    train_generator,\n","    epochs=25,\n","    validation_data=validation_generator\n",")\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = vgg16_model.evaluate(test_generator)\n","print(f\"Test accuracy: {test_acc:.4f}\")\n","\n","# Optionally save the model\n","vgg16_model.save('vgg16_model.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1732102061346,"user":{"displayName":"Assad Ullah","userId":"12251528893146048503"},"user_tz":-300},"id":"ocShyCYbDq9_","outputId":"6b5b500b-090e-411b-c834-1cfa90008784"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["# Define the VGG-16 architecture\n","model = models.Sequential()\n","\n","# Block 1\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=2))\n","\n","# Block 2\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=2))\n","\n","# Block 3\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=2))\n","\n","# Block 4\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=2))\n","\n","# Block 5\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(layers.MaxPooling2D((2, 2), strides=2))\n","\n","# Flatten and Fully Connected Layers\n","model.add(layers.Flatten())\n","model.add(layers.Dense(4096, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(4096, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","# model.add(layers.Dense(train_generator.num_classes, activation='softmax'))  # Adjust for number of classes\n","model.add(layers.Dense(3, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"St8aLyxeFPur"},"outputs":[],"source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355409,"status":"ok","timestamp":1732102425433,"user":{"displayName":"Assad Ullah","userId":"12251528893146048503"},"user_tz":-300},"id":"ec8gGCihFfVC","outputId":"cf948a11-932f-4bb0-ba4b-54c3a15a7d29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 657ms/step - accuracy: 0.3110 - loss: 1.1008 - val_accuracy: 0.4740 - val_loss: 1.0319\n","Epoch 2/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.9951\n","Epoch 3/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 615ms/step - accuracy: 0.3649 - loss: 1.1034 - val_accuracy: 0.3333 - val_loss: 1.0987\n","Epoch 4/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 1.0986\n","Epoch 5/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 642ms/step - accuracy: 0.3366 - loss: 1.0989 - val_accuracy: 0.3351 - val_loss: 1.0986\n","Epoch 6/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2917 - val_loss: 1.0987\n","Epoch 7/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 650ms/step - accuracy: 0.3305 - loss: 1.0986 - val_accuracy: 0.3576 - val_loss: 1.0969\n","Epoch 8/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 1.0952\n","Epoch 9/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 648ms/step - accuracy: 0.3423 - loss: 1.0990 - val_accuracy: 0.4358 - val_loss: 1.0976\n","Epoch 10/10\n","\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4167 - val_loss: 1.0977\n"]}],"source":["history = model.fit(\n","    train_generator,\n","    validation_data=val_generator,\n","    epochs=10,  # Adjust the number of epochs\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    validation_steps=val_generator.samples // val_generator.batch_size\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48rfNUtsGIqU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQ4LbN1wHMUbeek7bjmexw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}